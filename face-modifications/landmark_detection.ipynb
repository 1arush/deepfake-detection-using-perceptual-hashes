{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UaCZ3rFPptL_",
        "outputId": "80a45f98-c8c9-4e85-8430-1a8c7fd924cc"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "setup loading models"
      ],
      "metadata": {
        "id": "jt5I_530zRLt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import bz2\n",
        "import urllib.request\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Function to download the Dlib shape predictor model\n",
        "def download_shape_predictor():\n",
        "    url = \"http://dlib.net/files/shape_predictor_68_face_landmarks.dat.bz2\"\n",
        "    urllib.request.urlretrieve(url, \"shape_predictor_68_face_landmarks.dat.bz2\")\n",
        "    with bz2.BZ2File(\"shape_predictor_68_face_landmarks.dat.bz2\") as f:\n",
        "        with open(\"shape_predictor_68_face_landmarks.dat\", \"wb\") as out:\n",
        "            out.write(f.read())\n",
        "\n",
        "# Download Dlib shape predictor model\n",
        "download_shape_predictor()\n",
        "\n",
        "# Function to download the Haar Cascade files\n",
        "def download_haar_files():\n",
        "    base_url = \"https://github.com/opencv/opencv/raw/master/data/haarcascades/\"\n",
        "    haar_files = [\"haarcascade_frontalface_default.xml\", \"haarcascade_eye.xml\"]\n",
        "\n",
        "    for file in haar_files:\n",
        "        url = base_url + file\n",
        "        urllib.request.urlretrieve(url, file)\n",
        "\n",
        "# Download Haar Cascade files\n",
        "download_haar_files()"
      ],
      "metadata": {
        "id": "MWOo0g81zQ5_"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def save_cropped_image(cropped_image, save_path):\n",
        "    if cropped_image is None:\n",
        "        raise ValueError(\"Cropped image is None.\")\n",
        "\n",
        "    # Convert the image from BGR to RGB (since cv2.imread reads images in BGR format)\n",
        "    cropped_image_rgb = cv2.cvtColor(cropped_image, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "    # Save the image using matplotlib\n",
        "    os.makedirs(os.path.dirname(save_path), exist_ok=True)\n",
        "\n",
        "    plt.imsave(save_path, cropped_image_rgb)\n"
      ],
      "metadata": {
        "id": "DNBYEIYKzx4X"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def split_path_extension(pathname):\n",
        "    path, filename = os.path.split(pathname)\n",
        "    filename_base, file_extension = os.path.splitext(filename)\n",
        "    return os.path.join(path, filename_base), file_extension\n",
        "\n",
        "# name, ext = split_path_extension(image_path)"
      ],
      "metadata": {
        "id": "zGBgNw_wGnoX"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Eyes"
      ],
      "metadata": {
        "id": "6N_0TvmZ_K9o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load Haar Cascade classifiers\n",
        "face_cascade = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
        "eye_cascade = cv2.CascadeClassifier('haarcascade_eye.xml')\n",
        "\n",
        "# Verify that the Haar Cascades have been loaded correctly\n",
        "if face_cascade.empty():\n",
        "    raise IOError('Unable to load the face cascade classifier xml file.')\n",
        "if eye_cascade.empty():\n",
        "    raise IOError('Unable to load the eye cascade classifier xml file.')\n",
        "\n",
        "\n",
        "# Function to get the eye boxes\n",
        "def get_eye_boxes(image_path, face_cascade, eye_cascade):\n",
        "    image = cv2.imread(image_path)\n",
        "    if image is None:\n",
        "        raise ValueError(\"Image not found or path is incorrect.\")\n",
        "\n",
        "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    # Detect faces\n",
        "    faces = face_cascade.detectMultiScale(gray, 1.01, 4)\n",
        "    eye_boxes = []\n",
        "    for (x, y, w, h) in faces:\n",
        "        roi_gray = gray[y:y+h, x:x+w]\n",
        "\n",
        "        # Detect eyes within the face region\n",
        "        eyes = eye_cascade.detectMultiScale(roi_gray, 1.01, 4)\n",
        "\n",
        "        # Filter eyes to find the best pair\n",
        "        if len(eyes) >= 2:\n",
        "            eyes = sorted(eyes, key=lambda ex_ey_ew_eh: ex_ey_ew_eh[2] * ex_ey_ew_eh[3], reverse=True)  # Sort by size\n",
        "            best_eyes = eyes[:2]  # Take the two largest detections\n",
        "            best_eyes = sorted(best_eyes, key=lambda ex_ey_ew_eh: ex_ey_ew_eh[0])  # Sort by x position to ensure left-right order\n",
        "            for (ex, ey, ew, eh) in best_eyes:\n",
        "                eye_boxes.append((x + ex, y + ey, ew, eh))\n",
        "        return eye_boxes\n",
        "\n",
        "# Function to crop and return the eyes\n",
        "def detect_and_crop_eyes(image_path, eye_boxes):\n",
        "    image = cv2.imread(image_path)\n",
        "    if image is None:\n",
        "        raise ValueError(\"Image not found or path is incorrect.\")\n",
        "\n",
        "    eye_images = []\n",
        "    for (x, y, w, h) in eye_boxes:\n",
        "        eye_image = image[y:y+h, x:x+w]\n",
        "        eye_images.append(eye_image)\n",
        "\n",
        "    return eye_images"
      ],
      "metadata": {
        "id": "DsS8U9y4xKvG"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "base_path = '/content/drive/MyDrive/faces/'\n",
        "\n",
        "for typ in [\"m2\"]:\n",
        "    path = base_path + typ +'/'   #  '/content/drive/MyDrive/faces/f1/'\n",
        "    image_path = path + 'base/base.jpg'  #  '/content/drive/MyDrive/faces/f1/base/base.jpg'\n",
        "    fake_path = path + 'eyes/eyes.jpg'\n",
        "\n",
        "    eye_boxes = get_eye_boxes(image_path, face_cascade, eye_cascade)\n",
        "\n",
        "    real_images = detect_and_crop_eyes(image_path, eye_boxes)\n",
        "    fake_images = detect_and_crop_eyes(fake_path, eye_boxes)\n",
        "\n",
        "    for i, eye_image in enumerate(real_images):\n",
        "        save_cropped_image(eye_image,f'{path}base/eyebox_{i}.jpg')\n",
        "\n",
        "    for i, eye_image in enumerate(fake_images):\n",
        "        save_cropped_image(eye_image,f'{path}eyes/eyebox_{i}.jpg')\n",
        "\n"
      ],
      "metadata": {
        "id": "VeZyfKvgp9_G"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Mouth"
      ],
      "metadata": {
        "id": "0xHEmCbP_JHK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_mouth_bounding_box(image_path):\n",
        "    image = cv2.imread(image_path)\n",
        "    if image is None:\n",
        "        raise ValueError(\"Image not found or path is incorrect.\")\n",
        "\n",
        "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    # Detect faces\n",
        "    faces = detector(gray)\n",
        "    for face in faces:\n",
        "        x, y, w, h = (face.left(), face.top(), face.width(), face.height())\n",
        "\n",
        "        # Get the landmarks\n",
        "        shape = predictor(gray, face)\n",
        "        landmarks = np.zeros((68, 2), dtype=int)\n",
        "        for i in range(68):\n",
        "            landmarks[i] = (shape.part(i).x, shape.part(i).y)\n",
        "\n",
        "        # Get the mouth landmarks\n",
        "        mouth_landmarks = landmarks[48:68]\n",
        "        x_min = np.min(mouth_landmarks[:, 0])\n",
        "        x_max = np.max(mouth_landmarks[:, 0])\n",
        "        y_min = np.min(mouth_landmarks[:, 1])\n",
        "        y_max = np.max(mouth_landmarks[:, 1])\n",
        "\n",
        "        # Return bounding box coordinates\n",
        "        return (x_min, y_min, x_max, y_max)\n",
        "\n",
        "    # If no faces are detected, return None\n",
        "    return None\n",
        "\n",
        "\n",
        "def crop_mouth_region(image_path, bbox):\n",
        "    image = cv2.imread(image_path)\n",
        "    if image is None:\n",
        "        raise ValueError(\"Image not found or path is incorrect.\")\n",
        "\n",
        "    if bbox is None:\n",
        "        return None\n",
        "\n",
        "    x_min, y_min, x_max, y_max = bbox\n",
        "    cropped_mouth = image[y_min:y_max, x_min:x_max]\n",
        "\n",
        "    # Return cropped mouth image\n",
        "    return cropped_mouth"
      ],
      "metadata": {
        "id": "8HwiRMRnvhik"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Detect and crop mouth\n",
        "bbox = get_mouth_bounding_box('/content/base.jpg')\n",
        "cropped_mouth = crop_mouth_region('/content/base.jpg', bbox)\n",
        "save_cropped_image(cropped_mouth,'/content/mod.jpg')"
      ],
      "metadata": {
        "id": "BflMH16ezFkl"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "base_path = '/content/drive/MyDrive/faces/'\n",
        "\n",
        "for typ in [\"f1\",\"m1\",\"f2\",\"m2\"]:\n",
        "    path = base_path + typ +'/'   #  '/content/drive/MyDrive/faces/f1/'\n",
        "    image_path = path + 'base/base.jpg'  #  '/content/drive/MyDrive/faces/f1/base/base.jpg'\n",
        "    fake_path = path + 'lips/lips.jpg'\n",
        "    fake_m_path = path + 'lips_code/lips_code.jpg'\n",
        "\n",
        "    bbox = get_mouth_bounding_box(image_path)\n",
        "\n",
        "    real_images = crop_mouth_region(image_path, bbox)\n",
        "    fake_images = crop_mouth_region(fake_path, bbox)\n",
        "    fake_m_images = crop_mouth_region(fake_m_path, bbox)\n",
        "\n",
        "    save_cropped_image(real_images,f'{path}base/lipbox.jpg')\n",
        "    save_cropped_image(fake_images,f'{path}lips/lipbox.jpg')\n",
        "    save_cropped_image(fake_m_images,f'{path}lips_code/lipbox.jpg')\n"
      ],
      "metadata": {
        "id": "2M0budqnwKv4"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# nose"
      ],
      "metadata": {
        "id": "KFEbYj04xTOg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import dlib\n",
        "import urllib.request\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load Dlib's shape predictor\n",
        "predictor_path = \"shape_predictor_68_face_landmarks.dat\"\n",
        "predictor = dlib.shape_predictor(predictor_path)\n",
        "detector = dlib.get_frontal_face_detector()\n",
        "\n",
        "def get_nose_boxes(image_path):\n",
        "    image = cv2.imread(image_path)\n",
        "    if image is None:\n",
        "        raise ValueError(\"Image not found or path is incorrect.\")\n",
        "\n",
        "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    # Detect faces\n",
        "    faces = detector(gray)\n",
        "    for face in faces:\n",
        "        x, y, w, h = (face.left(), face.top(), face.width(), face.height())\n",
        "\n",
        "        # Get the landmarks\n",
        "        shape = predictor(gray, face)\n",
        "        landmarks = np.zeros((68, 2), dtype=int)\n",
        "        for i in range(68):\n",
        "            landmarks[i] = (shape.part(i).x, shape.part(i).y)\n",
        "\n",
        "        # Get the nose landmarks (adjust indices for a balanced nose region)\n",
        "        nose_landmarks = landmarks[27:36]  # Adjusted indices for a balanced nose region\n",
        "        x_min = np.min(nose_landmarks[:, 0])\n",
        "        x_max = np.max(nose_landmarks[:, 0])\n",
        "        y_min = np.min(nose_landmarks[:, 1])\n",
        "        y_max = np.max(nose_landmarks[:, 1])\n",
        "\n",
        "        return (x_min,x_max,y_min,y_max)\n",
        "    return (0,0,0,0)\n",
        "\n",
        "def crop_nose(image_path, bbox):\n",
        "    x_min, x_max, y_min, y_max = bbox\n",
        "    image = cv2.imread(image_path)\n",
        "\n",
        "    padding_x = 0.25  # 30% padding in width\n",
        "    padding_y = 0.1  # 10% padding in height\n",
        "    width = x_max - x_min\n",
        "    height = y_max - y_min\n",
        "    x_min = max(0, int(x_min - padding_x * width))\n",
        "    x_max = min(image.shape[1], int(x_max + padding_x * width))\n",
        "    y_min = max(0, int(y_min - padding_y * height))\n",
        "    y_max = min(image.shape[0], int(y_max + padding_y * height))\n",
        "    cropped_nose = image[y_min:y_max, x_min:x_max]\n",
        "    return cropped_nose"
      ],
      "metadata": {
        "id": "WWEtshW-_B8F"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Testing the code\n",
        "bbox = get_nose_boxes('/content/base.jpg')\n",
        "cropped_nose = crop_nose('/content/base.jpg',bbox)\n",
        "\n",
        "save_cropped_image(cropped_nose,'/content/nose.jpg')"
      ],
      "metadata": {
        "id": "Y8y0vLf93t73"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "base_path = '/content/drive/MyDrive/faces/'\n",
        "\n",
        "for typ in [\"f1\",\"m1\",\"f2\",\"m2\"]:\n",
        "    path = base_path + typ +'/'   #  '/content/drive/MyDrive/faces/f1/'\n",
        "    image_path = path + 'base/base.jpg'  #  '/content/drive/MyDrive/faces/f1/base/base.jpg'\n",
        "    fake_path = path + 'nose/nose.jpg'\n",
        "    fake_m_path = path + 'nose_code/nose_code.jpg'\n",
        "\n",
        "    bbox = get_nose_boxes(image_path)\n",
        "\n",
        "    real_images = crop_nose(image_path, bbox)\n",
        "    fake_images = crop_nose(fake_path, bbox)\n",
        "    fake_m_images = crop_nose(fake_m_path, bbox)\n",
        "\n",
        "    save_cropped_image(real_images,f'{path}base/nosebox.jpg')\n",
        "    save_cropped_image(fake_images,f'{path}nose/nosebox.jpg')\n",
        "    save_cropped_image(fake_m_images,f'{path}nose_code/nosebox.jpg')"
      ],
      "metadata": {
        "id": "7Q8I_GU2x76y"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Main code for a filepath"
      ],
      "metadata": {
        "id": "OlIdROri3hIb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "folder_path = '/content/drive/MyDrive/deepfake_images/face-swap'\n",
        "\n",
        "file_paths = []\n",
        "\n",
        "# Iterate through all the files and subdirectories in the given folder\n",
        "for root, _, files in os.walk(folder_path):\n",
        "    for file in files:\n",
        "        # Create the full file path and append it to the list\n",
        "        file_paths.append(os.path.join(root, file))\n",
        "\n",
        "print(file_paths)"
      ],
      "metadata": {
        "id": "N9NjfSQJqfJJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "444a7b53-d94f-4683-9c52-f04a5919373c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['/content/drive/MyDrive/deepfake_images/face-swap/woman_swap_1_2.jpg', '/content/drive/MyDrive/deepfake_images/face-swap/woman_swap_2_1.jpg', '/content/drive/MyDrive/deepfake_images/face-swap/man_swap_1_2.jpg', '/content/drive/MyDrive/deepfake_images/face-swap/man_swap_2_1.jpg']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "def detect_and_save_face_parts(image_path):\n",
        "    # Load image\n",
        "    name, ext = os.path.splitext(image_path)\n",
        "    nose_path = os.path.join(name+'_nose.jpg')\n",
        "    mouth_path = os.path.join(name+'_mouth.jpg')\n",
        "    l_eye_path = os.path.join(name+'_eyes_l.jpg')\n",
        "    r_eye_path = os.path.join(name+'_eyes_r.jpg')\n",
        "\n",
        "\n",
        "    image = cv2.imread(image_path)\n",
        "    if image is None:\n",
        "        raise ValueError(\"Image not found or path is incorrect.\")\n",
        "\n",
        "    # Detect and crop nose\n",
        "    bounding_box_nose, cropped_nose = detect_and_crop_nose(image_path)\n",
        "    save_cropped_image(cropped_nose, nose_path)\n",
        "\n",
        "    # Detect and crop eyes\n",
        "    eye_boxes = get_eye_boxes(image_path, face_cascade, eye_cascade)\n",
        "    cropped_eyes = detect_and_crop_eyes(image_path, eye_boxes)\n",
        "    for i, eye_image in enumerate(cropped_eyes):\n",
        "        path = ''\n",
        "        if i>0:\n",
        "            path = r_eye_path\n",
        "        else:\n",
        "            path = l_eye_path\n",
        "        save_cropped_image(eye_image,path)\n",
        "\n",
        "    # Detect and crop mouth\n",
        "    bounding_box_mouth, cropped_mouth = detect_and_crop_mouth(image_path)\n",
        "    save_cropped_image(cropped_mouth, mouth_path)\n",
        "\n",
        "detect_and_save_face_parts(image_path)\n"
      ],
      "metadata": {
        "id": "TArSSu3c1-sB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "for image_path in file_paths:\n",
        "    name = os.path.splitext(os.path.basename(image_path))[0]\n",
        "    detect_and_save_face_parts(image_path)"
      ],
      "metadata": {
        "id": "b93zTus8qt2n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Modifications to faces"
      ],
      "metadata": {
        "id": "R8Ygn8chqkb8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Working code"
      ],
      "metadata": {
        "id": "5YqYEZhOKwmb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import dlib\n",
        "import numpy as np\n",
        "import urllib.request\n",
        "\n",
        "# Load Dlib's shape predictor\n",
        "predictor_path = \"shape_predictor_68_face_landmarks.dat\"\n",
        "predictor = dlib.shape_predictor(predictor_path)\n",
        "detector = dlib.get_frontal_face_detector()\n",
        "\n",
        "# Function to detect facial landmarks (single face only)\n",
        "def detect_landmarks(image_path):\n",
        "    image = cv2.imread(image_path)\n",
        "    if image is None:\n",
        "        raise ValueError(\"Image not found or path is incorrect.\")\n",
        "\n",
        "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "    faces = detector(gray)\n",
        "    if len(faces) == 0:\n",
        "        raise ValueError(\"No faces detected in the image.\")\n",
        "\n",
        "    face = faces[0]  # Assume only one face for simplicity\n",
        "    landmarks = predictor(gray, face)\n",
        "    coords = np.zeros((68, 2), dtype=int)\n",
        "    for i in range(68):\n",
        "        coords[i] = (landmarks.part(i).x, landmarks.part(i).y)\n",
        "\n",
        "    return image, coords\n",
        "\n",
        "# Function to get the landmark points for each facial feature\n",
        "def get_feature_landmarks(coords):\n",
        "    features = {\n",
        "        'left_eye': coords[36:42],\n",
        "        'right_eye': coords[42:48],\n",
        "        'nose': coords[27:36],\n",
        "        'mouth': coords[48:68]\n",
        "    }\n",
        "    return features"
      ],
      "metadata": {
        "id": "v5x9o9jYKTgc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to smooth and enhance the nose region\n",
        "def beautify_nose(image, landmarks, sigma=15):\n",
        "    if image is None or landmarks is None:\n",
        "        raise ValueError(\"Image or landmarks cannot be None.\")\n",
        "\n",
        "    # Extract nose landmarks\n",
        "    nose_landmarks = landmarks['nose']\n",
        "    if nose_landmarks is None or len(nose_landmarks) == 0:\n",
        "        raise ValueError(\"Nose landmarks are not properly defined.\")\n",
        "\n",
        "    # Convert landmarks to numpy array for easier manipulation\n",
        "    nose_points = np.array(nose_landmarks)\n",
        "\n",
        "    # Get bounding box coordinates for the nose region\n",
        "    x, y, w, h = cv2.boundingRect(nose_points)\n",
        "\n",
        "    # Apply Gaussian blur to the nose region\n",
        "    nose_region = image[y:y+h, x:x+w]\n",
        "    blurred_nose = cv2.GaussianBlur(nose_region, (sigma, sigma), 0)\n",
        "\n",
        "    # Replace the nose region with the blurred version in the original image\n",
        "    image[y:y+h, x:x+w] = blurred_nose\n",
        "\n",
        "    return image\n",
        "\n",
        "# Function to enhance the lip color using landmarks\n",
        "def enhance_lips(image, landmarks, increment=30):\n",
        "    mouth = landmarks['mouth']\n",
        "    image = image.astype(np.uint8)\n",
        "\n",
        "    # Enhance lip color\n",
        "    mask = np.zeros_like(image)\n",
        "    points = mouth.reshape((-1, 1, 2))\n",
        "    cv2.fillPoly(mask, [points], (255, 255, 255))\n",
        "    hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
        "    hsv[:, :, 1] = np.where(mask[:, :, 1] == 255, cv2.add(hsv[:, :, 1], increment), hsv[:, :, 1])\n",
        "    enhanced = cv2.cvtColor(hsv, cv2.COLOR_HSV2BGR)\n",
        "\n",
        "    return enhanced\n"
      ],
      "metadata": {
        "id": "q3gIHheGKWYU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "USjsPkYdawNg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Run"
      ],
      "metadata": {
        "id": "dYh25xSEP0Z0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to smooth nose based on landmarks\n",
        "def modify_nose(image, landmarks):\n",
        "    return beautify_nose(image.copy(), landmarks)\n",
        "\n",
        "# Function to enhance lips based on landmarks\n",
        "def modify_lips(image, landmarks):\n",
        "    return enhance_lips(image.copy(), landmarks)"
      ],
      "metadata": {
        "id": "c1DgArMWKp88"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# !! main run code"
      ],
      "metadata": {
        "id": "UitY7SnM7z9I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "def process_current_image(image_path):\n",
        "    # Load the original image\n",
        "    image = cv2.imread(image_path)\n",
        "    if image is None:\n",
        "        raise ValueError(\"Image not found or path is incorrect.\")\n",
        "\n",
        "    # Detect landmarks and get feature landmarks\n",
        "    image, landmarks = detect_landmarks(image_path)\n",
        "    features = get_feature_landmarks(landmarks)\n",
        "\n",
        "    # Apply modifications independently\n",
        "    image_nose = modify_nose(image, features)\n",
        "    image_lips = modify_lips(image, features)\n",
        "\n",
        "    print(image.shape, image_nose.shape)\n",
        "    def split_path_extension(pathname):\n",
        "        path, filename = os.path.split(pathname)\n",
        "        filename_base, file_extension = os.path.splitext(filename)\n",
        "        return os.path.join(path, filename_base), file_extension\n",
        "\n",
        "    name, ext = split_path_extension(image_path)\n",
        "\n",
        "    # Save the modified images\n",
        "    save_cropped_image(image_nose, f\"{name}_nose_haar{ext}\")\n",
        "    save_cropped_image(image_lips, f\"{name}_lips_haar{ext}\")\n",
        "\n",
        "    print(\"All modified images saved successfully.\")"
      ],
      "metadata": {
        "id": "cikZli5o6WhD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "process_current_image('/content/woman_1.jpg')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9RqphiYPZQWr",
        "outputId": "f7cb278a-7fbd-4189-9305-a92cf8780882"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1024, 1024, 3) (1024, 1024, 3)\n",
            "All modified images saved successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "this is to contrast 2 images from each other"
      ],
      "metadata": {
        "id": "B4hO0UmC94vn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image, ImageDraw, ImageFont\n",
        "\n",
        "def concatenate_images_with_names(image_paths, output_path):\n",
        "    images = [Image.open(img_path) for img_path in image_paths]\n",
        "    widths, heights = zip(*(i.size for i in images))\n",
        "\n",
        "    total_width = sum(widths)\n",
        "    max_height = max(heights)\n",
        "\n",
        "    new_image = Image.new('RGB', (total_width, max_height), (255, 255, 255))\n",
        "\n",
        "    draw = ImageDraw.Draw(new_image)\n",
        "    font = ImageFont.load_default()\n",
        "\n",
        "    x_offset = 0\n",
        "    for idx, img in enumerate(images):\n",
        "        new_image.paste(img, (x_offset, 0))\n",
        "        draw.text((x_offset + img.width // 2, 10), image_paths[idx].split('/')[-1], fill=(0, 0, 0), font=font)\n",
        "        x_offset += img.width\n",
        "\n",
        "    new_image.save(output_path)\n",
        "\n",
        "# Example usage\n",
        "image_paths = ['/content/woman_2.jpg', '/content/modified_nose.jpg']\n",
        "output_path = '/content/woman_2_nose.jpg'\n",
        "\n",
        "concatenate_images_with_names(image_paths, output_path)\n"
      ],
      "metadata": {
        "id": "uBBr0imS6kaV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install imagehash"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sx6wT_de7glC",
        "outputId": "0e584dd9-568e-49a2-a663-f6689524a39e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting imagehash\n",
            "  Downloading ImageHash-4.3.1-py2.py3-none-any.whl (296 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m296.5/296.5 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: PyWavelets in /usr/local/lib/python3.10/dist-packages (from imagehash) (1.6.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from imagehash) (1.25.2)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (from imagehash) (9.4.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from imagehash) (1.11.4)\n",
            "Installing collected packages: imagehash\n",
            "Successfully installed imagehash-4.3.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# hash tests"
      ],
      "metadata": {
        "id": "2mkJeSxH7sNH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "import imagehash\n",
        "\n",
        "fake = Image.open('/content/modified_nose.jpg')\n",
        "real = Image.open(image_path)\n",
        "fh = imagehash.phash(fake)\n",
        "rh = imagehash.phash(real)\n",
        "\n",
        "print(fh, rh)\n",
        "print(fh - rh)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aEsbhPeW6Xlb",
        "outputId": "faa125cc-9ab1-43b1-c459-e7b7f47825c4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fae1258794dc9698 fae1258794dc9698\n",
            "0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "\n",
        "# Function to crop an image using bounding box coordinates and return the cropped region\n",
        "def crop_image_wrapper(image, bounding_box):\n",
        "    x_min, y_min, x_max, y_max = bounding_box\n",
        "\n",
        "    # Ensure the bounding box coordinates are within image dimensions\n",
        "    x_min = max(0, x_min)\n",
        "    y_min = max(0, y_min)\n",
        "    x_max = min(image.width, x_max)\n",
        "    y_max = min(image.height, y_max)\n",
        "\n",
        "    # Crop the image using the bounding box\n",
        "    cropped_image = image.crop((x_min, y_min, x_max, y_max))\n",
        "\n",
        "    return cropped_image\n"
      ],
      "metadata": {
        "id": "qIjq3sGu-xwL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "use the same bounding box for both images!"
      ],
      "metadata": {
        "id": "u0RnTAhTAGk9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def check_hashes(p1, p2):\n",
        "    im1 = Image.open(p1)\n",
        "    im2 = Image.open(p2)\n",
        "\n",
        "    # Detect and crop nose\n",
        "    bounding_box_nose1, cropped_nose1 = detect_and_crop_nose(p1)\n",
        "    im1 = crop_image_wrapper(im1,bounding_box_nose1)\n",
        "    im1.save('/content/01.jpg')\n",
        "    # save_cropped_image(cropped_nose1,'/content/original_hash.jpg')\n",
        "\n",
        "    bounding_box_nose2, cropped_nose2 = detect_and_crop_nose(p2)\n",
        "    im2 = crop_image_wrapper(im2,bounding_box_nose1)\n",
        "    im2.save('/content/02.jpg')\n",
        "    # save_cropped_image(cropped_nose2,'/content/fake_hash.jpg')\n",
        "\n",
        "\n",
        "    print(im1.size, im2.size)\n",
        "\n",
        "    rh = imagehash.phash(im1)\n",
        "    fh = imagehash.phash(im2)\n",
        "\n",
        "    print(fh, rh)\n",
        "\n",
        "check_hashes('/content/r_4.jpg','/content/modified_nose.jpg')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "Xu3QOUuQ7c5d",
        "outputId": "3d0a371e-35cf-4717-cc42-377852fc634c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(178, 233) (178, 233)\n",
            "c8813204ff7ce07f c8813604fe7ce07f\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "JZcR4r4vLyEX"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}